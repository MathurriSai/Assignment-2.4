1. Explain hadoop in layman's term
     
     HADOOP is a solution for big data in many ways.And the main concepts of hadoop are storage and processing. where HDFS is a platform for storing
     the huge sum of data where commodities machines where used and a huge pile of data can be stored in them. 
     
     Map reduce means one can write application to a huge amount of data at the same time since nodes connect all the slave devices.it takes 
     a set of data and it converts them into another set of data.And all the      data sent will stored as keys. which will be retrived when 
     the task is reduced after the maping is done. 
     it is of 2 stages:
     1.map:Input daat will be processed which will be in file formatan stored in HDFS. and by next line by line will be passed to mapper
     where the files will be stored into units.
     
     2.reduce:The work is to process the data coming from map and and once processed the new updates data will be stored in HDFS.
     
     PIG: it is a high level language in apache Hadoop where a user can write without any knowledge in java programming.it is like a simple SQL
     programming as well pig can invoke coding in many languages like jython and java.as well it can handle both structured as well unstructured
     data's.
     
     HIVE: it is a component of Hortonworks Data Platform(HDP).hive is a database query interface.where piga and hive seem to be similar
     Hive is considered friendlier and more familiar to users who are used to using SQL for querying data. Pig fits in through its data 
     flow strengths where it takes on the tasks of bringing data into Apache Hadoop and working with it to get it into the form for
     querying.
     


2. Explain the components of Hadoop framework

      Components of HADOO are classified into three: 1.)Map reduce: All the data which are stored in HDFS will be sent for processing to 
 map reduce where each and every line will be assigned to a block from slave machine.where it position will be marked.and the data will
 be written and later again will be stored into HDFS.
                                 2.)YARN: (Yet another Resource Negotiator)  is an advancement to Hadoop 1.0.YARN comes along with the
                                 Hadoop 2.x.YARN performs job scheduling and resource management.ARN has a modified architecture.so that the systems 
can scale up to new levels.
                                 3.)HDFS: it is the storage part of hadoop where all the n number of data will be assigned a slave 
 device.and saving and retriving becomes easy with the help of blocks since HDFS have 
       
    


3. Explain the reasons to learn Big data technologies
    
    There are data everywhere and there shouls be a found to manage those huge piles and one such is Big data where all the data's where
 storred and managed. it is a trending technology whose demand tends to increase each day.and if a person is well and good in big data
 they are capable of making core decision making. as well in the near by future there will be a hugr freelancing opportunities.And one 
 must learn the upcoming trenda to succeed in this world.
   77% of top organizations consider data analytics a critical component of business performance.




